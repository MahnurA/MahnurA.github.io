---
layout: post
title:  "Dataset Troubles"
date:   2019-03-02
categories: ['Final Year Project']
---
Category: **Final Year Project**

Every machine learning project needs data, training data, test data, attack data, benign, mixed etc etc. When we (my team members) and I started on this project the very first problem we hit was where to get labelled data of network attacks from. 

### **Intrusion Detection Evaluation Dataset** [(CICIDS2017)](https://www.unb.ca/cic/datasets/ids-2017.html) ###

This is the dataset that I was first introduced to through one of my professor's colleague who was also using it for her projects. CICIDS 2017 dataset is data generated by the Canadian Institute of Cybersecurity (CIC).The main aim of this dataset was to generate data that is as accurate as can be in its resemblance to real world network traffic. 

Existing datasets are mostly out of data due to the rapidly evolving way in which network attacks take place and the infrastructure they target. In the related [research paper](http://www.scitepress.org/Papers/2018/66398/66398.pdf), the authors evaluate the shortcomings of eleven existing datasets, concluding that *"some of these datasets suffer from the lack of traffic diversity and volumes, some do not cover the variety of known attacks, while others anonymize packet payload data, which cannot reflect the current trends. Some are also lacking feature set and metadata."*

Thus, the authors sought to create a dataset that addressed all these problems and would be the most comprehensive dataset to data. 8 attacks are covered in this dataset: **Brute Force SSH** and **SFTP**, **Hearbleed**, **Botnet**, **Denial of service**, **Distributed Denial of Service**, **SQL Injection**, **Cross-site scripting**, and **Infiltration attack** that they define as, *"infiltration of the network from inside by normally exploiting a vulnerable software such as Adobe Acrobat Reader. After successful exploitation, a backdoor will be executed on the victim’s computer and can conduct different attacks on the victim’s network such as IP sweep, full port scan and service enumerations using Nmap."*

**Why this dataset was not used?**

Seemingly this data seemed to be perfect, but upon later inspection we realized it was too perfect. Using deep learning, my professor's colleague, who had used this as something to practice on, found the accuracy to be nearly 99% according to the model she used. This showed that their was little to no variation in the same type of attack. 

Also, benign data here, is generated by using a B-profile system which mirrors normal abstract behaviour of users surfing and carrying out their activities on the internet. However, the way the B-profile system works exactly and how it's used to train the agent which then generates realistic events is not published anywhere. So, I had considerable difficulty in trying to ascertain how exactly human interaction on the internet was being reconstructed by this system. The deep learning approach also showed that this benign background traffic data was being generated in a predictable pattern which was against how such data should be. 

Another problem was that the pcaps for this dataset as a whole amounted to nearly 48 GB, with each pcap being on average around 9 GB. The total volume made this dataset made it very hard to handle. It could easily have been a lot smaller while still keeping all the attack data. 

Finally, since this dataset had been created in the lab at University of New Brunswick, with the lab setup as outlined in the research paper, the dataset would need to be considerably modified to be replayed in a live environment which was one of the requirements of this project.

All these factors made it difficult to use this dataset.

### **Other options** ###

1. One of the most obvious options for obtaining a dataset was to contact local tech companies focused on cyber security and might have honeypots set up. Or to set up a honeypot ourselves. The latter option could not be considered due to the time constraint. <br/>
The major roadblock that we faced here was the time delay it took in contacting such companies, and the back and forth correspondence in trying to explain our needs and requirements. Also, what hadn't been considered but later became the reason this option was not pursued, was that even if data from some honeypot could be obtained that raw data would not be tagged. It would be almost impossible to identify what attack happened where in the network traffic pcap and tag it accurately. 

2. Look for other datasets online, and consider merging them together. This was abandoned due to a lack of recent datasets available for free usage. 

3. Create our own dataset. 

### **Option 3: To create or not to create?** ###

Generating your own network traffic data is notoriously discouraged in projects such as this one where machine learning is being used to classify network attacks. This is due to an unending multitude of reasons some of which are: 
1. Network traffic intentionally generated in an isolated environment is rarely comparable to the traffic that firewalls and Intrusion Prevention Systems in corporate networks have to deal with. 
2. Time consuming to set up a live isolated environment.
3. Hard to obtain all the required hardware, space and be able to occupy it for as long as needed which can easily amount to many months. 

Despite all of this we still decided to generate our own network traffic and create the dataset. One of the major reasons for doing this was since the data needed to be tagged and would later need to either be replayed or attacks would need to be shown in a live environment, it would be much easier to use data that we were familiar with and had generated ourselves so would know precisely which attack was done how, when and for how long. 

### **The Dataset** ###

For creating our own dataset what was first required was defining which attacks exactly would be included. This would then be the basis of setting up the required network infrastructure and environments on each computer. 

The attacks decided upon were: 
1. Portscan 
2. Brute force SSH
3. SQL injection
4. Cross-site scripting 
5. Denial of Service 
6. Distributed Denial of Service
7. Botnet 
8. Ransomeware



